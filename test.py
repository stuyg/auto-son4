import os
import gc
import h5py
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å‹
from model import GCN_CSS, CNN_CSS, MLP_CSS 

# ================= é…ç½®åŒºåŸŸ =================
HDF5_PATH = '/root/autodl-tmp/radioml2018/GCN_CSS/GOLD_XYZ_OSC.0001_1024.hdf5' 
BATCH_SIZE = 32  
NUM_NODES = 32
TARGET_PFA = 0.1 
SAMPLES_PER_SNR = 100 # æ¢å¤é‡‡æ ·æ•°ï¼Œä¿è¯æ›²çº¿å¹³æ»‘

# å¼ºåˆ¶ä½¿ç”¨ CPU (é¿å… GPU OOMï¼Œè™½ç„¶æ…¢ç‚¹ä½†ç¨³)
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

MODELS = [
    {'name': 'GCN-CSS (Proposed)', 'class': GCN_CSS, 'path': 'best_gcn_model.h5', 'color': 'red', 'marker': 'o', 'type': 'gcn'},
    {'name': 'CNN', 'class': CNN_CSS, 'path': 'best_cnn_model.h5', 'color': 'blue', 'marker': 's', 'type': 'other'},
    {'name': 'MLP', 'class': MLP_CSS, 'path': 'best_mlp_model.h5', 'color': 'green', 'marker': '^', 'type': 'other'},
]

# ================= æ•°æ®åŠ è½½ (ä¿®å¤ç‰ˆ) =================
def load_random_test_data(hdf5_path, samples_per_snr=100):
    print(f"ğŸš€ æ­£åœ¨åŠ è½½æµ‹è¯•æ•°æ® (æ¯SNRé‡‡æ ·: {samples_per_snr})...")
    with h5py.File(hdf5_path, 'r') as f:
        Z_all = f['Z'][:]
        unique_snrs = np.unique(Z_all)
        
        selected_indices = []
        np.random.seed(2024)
        for snr in unique_snrs:
            indices = np.where(Z_all == snr)[0]
            if len(indices) > samples_per_snr:
                chosen = np.random.choice(indices, samples_per_snr, replace=False)
            else:
                chosen = indices
            selected_indices.extend(chosen)
        selected_indices = np.sort(np.array(selected_indices))
        
        # åˆ†å—è¯»å– X
        X_chunks = []
        chunk_size = 2000 
        for i in range(0, len(selected_indices), chunk_size):
            subset = selected_indices[i : i + chunk_size]
            X_chunks.append(f['X'][subset])
        
        X_sig = np.concatenate(X_chunks, axis=0)
        Z_sig = Z_all[selected_indices]
        
        # ã€å…³é”®ä¿®æ­£ã€‘: å‡†ç¡®ä¼°ç®—åº•å™ª (Noise Floor)
        # ä½¿ç”¨ -20dB çš„ä¿¡å·ä½œä¸ºåº•å™ªå‚è€ƒ (æ­¤æ—¶ä¿¡å·æ·¹æ²¡åœ¨å™ªå£°ä¸­ï¼Œæ¥è¿‘çº¯å™ªå£°)
        noise_floor_indices = np.where(Z_all == -20)[0]
        if len(noise_floor_indices) == 0:
            # å¦‚æœæ²¡æœ‰ -20dBï¼Œæ‰¾æœ€å°çš„é‚£ä¸ª SNR
            min_snr = np.min(Z_all)
            noise_floor_indices = np.where(Z_all == min_snr)[0]
            print(f"âš ï¸ æœªæ‰¾åˆ° -20dB æ•°æ®ï¼Œä½¿ç”¨ {min_snr}dB ä¼°ç®—åº•å™ª")
            
        # åªå–å‰ 2000 ä¸ªæ ·æœ¬è®¡ç®— stdï¼ŒèŠ‚çœå†…å­˜
        idx_floor = noise_floor_indices[:2000]
        # éœ€è¦é‡æ–°ä»æ–‡ä»¶è¯»å–è¿™éƒ¨åˆ†çº¯åº•å™ªæ•°æ®
        X_floor = f['X'][idx_floor]
        noise_std = np.std(X_floor)
        print(f"ğŸ“‰ ä¼°è®¡çš„ç‰©ç†åº•å™ª Std: {noise_std:.6f}")

    # ç”Ÿæˆ H0 å™ªå£°
    # è¿™é‡Œçš„å™ªå£°åŠŸç‡å¿…é¡»ä¸æ•°æ®é›†çš„åº•å™ªä¸€è‡´ï¼Œæ¨¡å‹æ‰èƒ½æ­£ç¡®åŒºåˆ†
    X_noise = np.random.normal(0, noise_std, size=X_sig.shape).astype(np.float32)
    Z_noise = np.full((len(X_sig), 1), -100.0)
    
    X = np.concatenate([X_noise, X_sig], axis=0)
    Y = np.concatenate([np.zeros(len(X_sig)), np.ones(len(X_sig))])
    Z = np.concatenate([Z_noise, Z_sig])
    
    # ã€é‡è¦ã€‘åˆ é™¤äº† Z-Score å½’ä¸€åŒ–ï¼
    # ä¿æŒ X çš„åŸå§‹å¹…åº¦ï¼Œå› ä¸ºè®­ç»ƒæ—¶å¹¶æœªå½’ä¸€åŒ–
    
    del X_chunks, X_sig, X_noise, Z_all, X_floor
    gc.collect()
    
    print(f"âœ… æ•°æ®å°±ç»ª: {X.shape}")
    return X, Y, Z.flatten()

# ================= æ‰¹å¤„ç† =================
def process_batch(X_raw, is_gcn=True):
    feat_dim = 1024 * 2 // NUM_NODES
    X_r = X_raw.reshape(-1, NUM_NODES, feat_dim)
    X_t = tf.convert_to_tensor(X_r, dtype=tf.float32)
    
    if is_gcn:
        # GCN è®¡ç®—é‚»æ¥çŸ©é˜µ
        diff = tf.expand_dims(X_t, 2) - tf.expand_dims(X_t, 1)
        dist = tf.reduce_sum(tf.square(diff), axis=-1)
        A = tf.exp(-dist) 
        D = tf.reduce_sum(A, axis=-1, keepdims=True)
        A = A / (D + 1e-6)
        return [X_t, A]
    else:
        # CNN/MLP ä¼  Dummy Tensor
        batch_size = tf.shape(X_t)[0]
        dummy = tf.zeros((batch_size, 1), dtype=tf.float32)
        return [X_t, dummy]

def get_predictions(model_cfg, X):
    print(f"ğŸ¤– æ­£åœ¨è¯„ä¼°: {model_cfg['name']}...")
    tf.keras.backend.clear_session()
    gc.collect()
    
    model = model_cfg['class'](2, NUM_NODES)
    try:
        model.build([(None, NUM_NODES, 64), (None, NUM_NODES, NUM_NODES)])
        model.load_weights(model_cfg['path'])
    except Exception as e:
        print(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
        return None
        
    preds = []
    total = len(X)
    is_gcn = (model_cfg['type'] == 'gcn')
    
    for i in range(0, total, BATCH_SIZE):
        bx = X[i : i+BATCH_SIZE]
        inputs = process_batch(bx, is_gcn=is_gcn)
        p = model.predict_on_batch(inputs)
        preds.append(p[:, 1])
        
        if i % (BATCH_SIZE * 50) == 0:
            print(f"   è¿›åº¦: {i}/{total}", end='\r')
            gc.collect()
            
    print(f"   è¿›åº¦: {total}/{total}")
    return np.concatenate(preds)

def plot_charts(results, Y_true, Z_snr):
    # å›¾ 1: Pd vs SNR
    plt.figure(figsize=(10, 6))
    snr_range = np.arange(-20, 31, 2)
    
    for name, scores in results.items():
        cfg = next(c for c in MODELS if c['name'] == name)
        
        # è®¡ç®—é˜ˆå€¼
        noise_scores = scores[Y_true == 0]
        thresh = np.percentile(noise_scores, (1 - TARGET_PFA)*100)
        
        pd_list = []
        for snr in snr_range:
            idx = np.where((Y_true == 1) & (np.abs(Z_snr - snr) < 1.0))[0]
            if len(idx) == 0: 
                pd_list.append(0)
            else:
                pd = np.mean(scores[idx] > thresh)
                pd_list.append(pd)
            
        plt.plot(snr_range, pd_list, label=name, color=cfg['color'], marker=cfg['marker'])
                 
    plt.title(f'Detection Probability vs SNR ($P_{{fa}}={TARGET_PFA}$)')
    plt.xlabel('SNR (dB)')
    plt.ylabel('Pd')
    plt.xlim([-20, 30])
    plt.ylim([0, 1.05])
    plt.grid(True)
    plt.legend()
    plt.savefig('real_pd_vs_snr_fixed.png')
    print("âœ… å›¾1 ä¿å­˜æˆåŠŸ: real_pd_vs_snr_fixed.png")

    # å›¾ 2: ROC
    plt.figure(figsize=(8, 8))
    target_snr = -10
    sig_idx = np.where((Y_true == 1) & (np.abs(Z_snr - target_snr) < 1.0))[0]
    noise_idx = np.where(Y_true == 0)[0]
    
    if len(sig_idx) > 0:
        y_roc = np.concatenate([np.zeros(len(noise_idx)), np.ones(len(sig_idx))])
        for name, scores in results.items():
            cfg = next(c for c in MODELS if c['name'] == name)
            s_roc = np.concatenate([scores[noise_idx], scores[sig_idx]])
            fpr, tpr, _ = roc_curve(y_roc, s_roc)
            plt.plot(fpr, tpr, label=f"{name} (AUC={auc(fpr, tpr):.4f})", color=cfg['color'])
            
    plt.plot([0, 1], [0, 1], 'k--')
    plt.title(f'ROC at {target_snr}dB')
    plt.legend()
    plt.savefig('real_roc_curve_fixed.png')
    print("âœ… å›¾2 ä¿å­˜æˆåŠŸ: real_roc_curve_fixed.png")

if __name__ == "__main__":
    X, Y, Z = load_random_test_data(HDF5_PATH, samples_per_snr=SAMPLES_PER_SNR)
    
    results = {}
    for m in MODELS:
        s = get_predictions(m, X)
        if s is not None: results[m['name']] = s
            
    if results: plot_charts(results, Y, Z)