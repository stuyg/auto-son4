import h5py
import numpy as np
import tensorflow as tf
import math

class RadioMLSequence(tf.keras.utils.Sequence):
    def __init__(self, hdf5_path, batch_size, indices, num_antennas=2, mode='binary', fading='rayleigh'):
        """
        num_antennas (M): å¤©çº¿æ•°é‡ã€‚å›¾çš„èŠ‚ç‚¹æ•°å°†ç­‰äºæ­¤å€¼ã€‚
        fading: 'rayleigh' (ç‘åˆ©), 'rician' (è±æ–¯), 'awgn' (æ— è¡°è½)
        """
        self.hdf5_path = hdf5_path
        self.batch_size = batch_size
        self.indices = indices
        self.num_nodes = num_antennas  # è¿™é‡Œçš„èŠ‚ç‚¹å³å¤©çº¿
        self.mode = mode
        self.fading = fading
        self.num_classes = 2 if mode == 'binary' else 24
        
        # æ¯ä¸ªå¤©çº¿æ¥æ”¶å®Œæ•´çš„ 1024 ä¸ª IQ æ ·æœ¬ (1024 * 2 = 2048 ç‰¹å¾)
        self.feature_dim = 2048 
        
        print(f"ğŸ“¡ åˆå§‹åŒ–å¤šå¤©çº¿ç”Ÿæˆå™¨: M={self.num_nodes} Antennas, Fading={fading}...")
        
        # é¢„åŠ è½½åº•å™ªä¿¡æ¯
        with h5py.File(self.hdf5_path, 'r') as f:
            # ç®€å•ä¼°ç®—æ•°æ®é›†çš„åº•å™ª (å‡è®¾å‰1000ä¸ªæ ·æœ¬åŒ…å«å™ªå£°)
            sample_X = f['X'][:1000]
            self.dataset_noise_std = np.std(sample_X)

        self.local_indices = np.arange(len(self.indices))
        np.random.shuffle(self.local_indices)
        self.total_len = len(self.indices)

    def __len__(self):
        return math.ceil(self.total_len / self.batch_size)

    def apply_fading_and_noise(self, X_source, M):
        """
        æ¨¡æ‹Ÿ SIMO (å•å‘å¤šæ”¶) ä¿¡é“
        X_source: (Batch, 1024, 2) - åŸå§‹å‘å°„ä¿¡å·
        M: å¤©çº¿æ•°
        """
        batch_size = X_source.shape[0]
        # è½¬ä¸ºå¤æ•°ä¾¿äºè®¡ç®—
        s = X_source[..., 0] + 1j * X_source[..., 1] # (Batch, 1024)
        
        # 1. ç”Ÿæˆä¿¡é“ç³»æ•° h (Batch, M, 1)
        if self.fading == 'rayleigh':
            # ç‘åˆ©è¡°è½: å®éƒ¨è™šéƒ¨ ~ N(0, 1/sqrt(2))
            h = (np.random.normal(0, 1, (batch_size, M, 1)) + 
                 1j * np.random.normal(0, 1, (batch_size, M, 1))) / np.sqrt(2)
                 
        elif self.fading == 'rician':
            # è±æ–¯è¡°è½ (K=10): æœ‰è§†è·åˆ†é‡
            k_factor = 10.0
            mu = np.sqrt(k_factor / (k_factor + 1))
            sigma = np.sqrt(1 / (2 * (k_factor + 1)))
            h_los = mu
            h_scat = sigma * (np.random.normal(0, 1, (batch_size, M, 1)) + 
                              1j * np.random.normal(0, 1, (batch_size, M, 1)))
            h = h_los + h_scat
            
        else: # awgn only (h=1)
            h = np.ones((batch_size, M, 1), dtype=np.complex64)
            
        # 2. ä¿¡å·é€šè¿‡ä¿¡é“: y = h * s
        # (Batch, M, 1) * (Batch, 1, 1024) -> (Batch, M, 1024)
        s_expanded = np.expand_dims(s, 1) 
        y_clean = h * s_expanded 
        
        # 3. ç”Ÿæˆç‹¬ç«‹å™ªå£° (æ¯ä¸ªå¤©çº¿å™ªå£°ä¸åŒ)
        # ä½¿ç”¨æ•°æ®é›†åŸæœ¬çš„ noise level ä½œä¸ºåŸºå‡†
        n = (np.random.normal(0, self.dataset_noise_std, (batch_size, M, 1024)) + 
             1j * np.random.normal(0, self.dataset_noise_std, (batch_size, M, 1024)))
        
        y_noisy = y_clean + n
        
        # è½¬å›å®æ•° (Batch, M, 1024, 2)
        y_out = np.stack([np.real(y_noisy), np.imag(y_noisy)], axis=-1)
        return y_out.astype(np.float32)

    def __getitem__(self, idx):
        start = idx * self.batch_size
        end = min((idx + 1) * self.batch_size, self.total_len)
        
        # è·å–å½“å‰ batch åœ¨ shuffled åˆ—è¡¨ä¸­çš„ä½ç½®
        batch_idx_in_local = self.local_indices[start:end]
        
        # è·å–å¯¹åº”çš„çœŸå®æ–‡ä»¶ç´¢å¼•
        batch_file_indices = self.indices[batch_idx_in_local]
        
        # ã€å…³é”®ä¿®å¤ã€‘h5py è¦æ±‚ç´¢å¼•å¿…é¡»æ’åº
        sorted_indices = np.sort(batch_file_indices)
        
        with h5py.File(self.hdf5_path, 'r') as f:
            X_batch = f['X'][sorted_indices]
            
        # ä¸ºäº†é¿å…å› ä¸ºæ’åºå¯¼è‡´çš„æ ·æœ¬åå·®ï¼Œè¯»å–åå†æ‰“ä¹±ä¸€æ¬¡é¡ºåº
        np.random.shuffle(X_batch)
        
        current_bs = X_batch.shape[0]
        
        if self.mode == 'binary':
            # æ„é€ æ ‡ç­¾: ä¸€åŠä¿¡å·ï¼Œä¸€åŠå™ªå£°
            Y_batch = np.zeros((current_bs, 2), dtype=np.float32)
            sig_len = current_bs // 2
            
            # 1. ä¿¡å·éƒ¨åˆ† (Label=[0, 1])
            Y_batch[:sig_len, 1] = 1.0 
            
            # ä½¿ç”¨ batch çš„å‰åŠéƒ¨åˆ†ä½œä¸ºä¿¡å·æº
            X_sig_source = X_batch[:sig_len]
            # åº”ç”¨è¡°è½ç”Ÿæˆå¤šå¤©çº¿ä¿¡å·
            X_sig_final = self.apply_fading_and_noise(X_sig_source, self.num_nodes)
            
            # 2. å™ªå£°éƒ¨åˆ† (Label=[1, 0])
            Y_batch[sig_len:, 0] = 1.0
            # å™ªå£°ä¸éœ€è¦ä¿¡é“ï¼Œç›´æ¥ç”Ÿæˆ M è·¯ç‹¬ç«‹å™ªå£°
            X_noise_final = np.random.normal(0, self.dataset_noise_std, 
                                           (current_bs - sig_len, self.num_nodes, 1024, 2)).astype(np.float32)
            
            X_final = np.concatenate([X_sig_final, X_noise_final], axis=0)
        else:
            # éäºŒåˆ†ç±»æ¨¡å¼ç›´æ¥å…¨éƒ¨åº”ç”¨è¡°è½
            X_final = self.apply_fading_and_noise(X_batch, self.num_nodes)
            Y_batch = None 

        # --- æ„å›¾å‡†å¤‡ ---
        # æ¨¡å‹è¾“å…¥æœŸæœ›: [X, A]
        # X shape: (Batch, M, 2048) -> å±•å¹³ IQ ç»´
        X_reshaped = X_final.reshape(current_bs, self.num_nodes, -1)
        
        # è®¡ç®—ç©ºé—´ç›¸å…³æ€§ (ä½™å¼¦ç›¸ä¼¼åº¦)
        norm = np.linalg.norm(X_reshaped, axis=2, keepdims=True) + 1e-8
        X_norm = X_reshaped / norm
        sim_matrix = np.matmul(X_norm, np.transpose(X_norm, (0, 2, 1))) # (B, M, M)
        
        # æ„å›¾ (ç»å¯¹å€¼ç›¸ä¼¼åº¦)
        A_batch = np.abs(sim_matrix)
        
        # å¯¹ç§°å½’ä¸€åŒ–
        D = np.sum(A_batch, axis=-1, keepdims=True)
        D_inv_sqrt = np.power(D + 1e-6, -0.5)
        A_norm = D_inv_sqrt * A_batch * np.transpose(D_inv_sqrt, (0, 2, 1))
        
        return [X_reshaped, A_norm.astype(np.float32)], Y_batch

    def on_epoch_end(self):
        np.random.shuffle(self.local_indices)

def get_generators(hdf5_path, batch_size=32, num_nodes=2, split_ratio=0.8, max_samples=None, fading='rayleigh'):
    with h5py.File(hdf5_path, 'r') as f:
        total = f['X'].shape[0]
    if max_samples: total = min(total, max_samples)
    
    indices = np.arange(total)
    np.random.shuffle(indices)
    split = int(total * split_ratio)
    
    # æ³¨æ„: num_nodes ä¼ ç»™ Sequence ä½œä¸º num_antennas
    train_gen = RadioMLSequence(hdf5_path, batch_size, indices[:split], num_antennas=num_nodes, mode='binary', fading=fading)
    val_gen = RadioMLSequence(hdf5_path, batch_size, indices[split:], num_antennas=num_nodes, mode='binary', fading=fading)
    
    return train_gen, val_gen, 2, train_gen.feature_dim