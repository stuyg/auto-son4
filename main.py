import os
import argparse

# ==========================================
# 1. æ˜¾å­˜é…ç½® (åŠ¡å¿…æ”¾åœ¨ import tensorflow ä¹‹å‰)
# ==========================================
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf

gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"âœ… [GPU] å·²æ£€æµ‹åˆ° {len(gpus)} ä¸ª GPUï¼Œæ˜¾å­˜åŠ¨æ€å¢é•¿å·²å¼€å¯ã€‚")
    except RuntimeError as e:
        print(f"âŒ æ˜¾å­˜è®¾ç½®å¤±è´¥: {e}")
else:
    print("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œå°†ä½¿ç”¨ CPU è¿è¡Œã€‚")

# ==========================================
# 2. å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
# ==========================================
from dataset import get_generators 
from model import GCN_CSS, CNN_CSS, MLP_CSS, GAT_CSS,CNN_GCN_CSS
from training import train_model

def main():
    parser = argparse.ArgumentParser(description="GCN/CNN/MLP Spectrum Sensing")
    parser.add_argument('--path', type=str, required=True, help='Path to .hdf5 dataset')
    parser.add_argument('--model_type', type=str, default='gcn', choices=['gcn', 'cnn', 'mlp', 'gat','cnn_gcn'], help='Choose model architecture')
    parser.add_argument('--epochs', type=int, default=10)
    parser.add_argument('--batch_size', type=int, default=32) 
    parser.add_argument('--nodes', type=int, default=32)
    parser.add_argument('--lr', type=float, default=0.001)
    parser.add_argument('--samples', type=int, default=None)
    
    # ã€æ–°å¢ã€‘æ”¯æŒæ–­ç‚¹ç»­è®­çš„å‚æ•°
    parser.add_argument('--resume', action='store_true', help='Resume training from the best checkpoint if available')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ æ­£åœ¨å‡†å¤‡æ•°æ®ç”Ÿæˆå™¨ (Nodes={args.nodes})...")
    
    # è·å–ç”Ÿæˆå™¨
    train_gen, val_gen, num_classes, num_features = get_generators(
        hdf5_path=args.path,
        batch_size=args.batch_size,
        num_nodes=args.nodes,
        split_ratio=0.8,
        max_samples=args.samples
    )
    
    print(f"ç”Ÿæˆå™¨å‡†å¤‡å®Œæ¯•ã€‚åˆ†ç±»æ•°: {num_classes}, èŠ‚ç‚¹ç‰¹å¾ç»´æ•°: {num_features}")
    
    # æ ¹æ®å‚æ•°é€‰æ‹©æ¨¡å‹å’Œä¿å­˜è·¯å¾„
    if args.model_type == 'gcn':
        print("æ„å»º GCN æ¨¡å‹...")
        model = GCN_CSS(num_classes=num_classes, num_nodes=args.nodes)
        save_name = 'best_gcn_model.h5'
    elif args.model_type == 'cnn':
        print("æ„å»º CNN æ¨¡å‹...")
        model = CNN_CSS(num_classes=num_classes, num_nodes=args.nodes)
        save_name = 'best_cnn_model.h5'
    elif args.model_type == 'mlp':
        print("æ„å»º MLP æ¨¡å‹...")
        model = MLP_CSS(num_classes=num_classes, num_nodes=args.nodes)
        save_name = 'best_mlp_model.h5'
    elif args.model_type == 'gat':
        print("æ„å»º GAT (Graph Transformer) æ¨¡å‹...")
        model = GAT_CSS(num_classes=num_classes, num_nodes=args.nodes)
        save_name = 'best_gat_model.h5'
    elif args.model_type == 'cnn_gcn':
        print("æ„å»º CNN-GCN èåˆæ¨¡å‹ (SOTA)...")
        model = CNN_GCN_CSS(num_classes=num_classes, num_nodes=args.nodes)
        save_name = 'best_cnngcn_model.h5'
    
    # Build æ¨¡å‹
    # GCN éœ€è¦ä¸¤ä¸ªè¾“å…¥ï¼ŒCNN/MLP ä¸ºäº†æ¥å£ç»Ÿä¸€ä¹Ÿbuildæˆç›¸åŒå½¢çŠ¶
    model.build([(None, args.nodes, num_features), (None, args.nodes, args.nodes)])
    model.summary()
    
    # ã€æ–°å¢ã€‘æ–­ç‚¹ç»­è®­é€»è¾‘
    if args.resume:
        if os.path.exists(save_name):
            print(f"ğŸ”„ æ£€æµ‹åˆ°æ–­ç‚¹ç»­è®­è¯·æ±‚ï¼Œæ­£åœ¨åŠ è½½æƒé‡: {save_name}")
            try:
                model.load_weights(save_name)
                print("âœ… æƒé‡åŠ è½½æˆåŠŸï¼Œå°†åŸºäºç°æœ‰æ¨¡å‹ç»§ç»­è®­ç»ƒã€‚")
            except Exception as e:
                print(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}ï¼Œå°†é‡æ–°å¼€å§‹è®­ç»ƒã€‚")
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶ {save_name}ï¼Œæ— æ³•ç»­è®­ï¼Œå°†é‡æ–°å¼€å§‹è®­ç»ƒã€‚")
    
    # å¼€å§‹è®­ç»ƒ
    train_model(model, train_gen, val_gen, epochs=args.epochs, lr=args.lr, save_path=save_name)

if __name__ == "__main__":
    main()